{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8d6b84-4754-447f-b37f-35a3649bec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.common import *\n",
    "from models.vae_gaussian import *\n",
    "from models.vae_flow import *\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010d917d-9d02-4ea4-919e-084d2cc32236",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688f88d1",
   "metadata": {},
   "source": [
    "## Load the pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71f8177-ef7e-49dc-a84d-8480456768e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load('logs_gen/Line_sim/ckpt_0.000000_1000000.pt', map_location=torch.device(device))\n",
    "model_sim = GaussianVAE(ckpt['args']).to(device)\n",
    "model_sim.load_state_dict(ckpt['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6093c4-5b6c-4f40-8b05-35e776bac246",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load('logs_gen/Line_exp/ckpt_0.000000_1000000.pt', map_location=torch.device(device))\n",
    "model_exp = GaussianVAE(ckpt['args']).to(device)\n",
    "model_exp.load_state_dict(ckpt['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2730f58",
   "metadata": {},
   "source": [
    "## Load Datasets for translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9099315-c943-473d-bec9-cac8f489721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "sim_data = np.load('data/toy/line.npy')\n",
    "exp_data = np.load('data/toy/line_noisy.npy')\n",
    "# Convert to PyTorch Tensors\n",
    "sim_data = torch.from_numpy(sim_data).float()\n",
    "exp_data = torch.from_numpy(exp_data).float()\n",
    "\n",
    "# Create TensorDatasets\n",
    "sim_dset = TensorDataset(sim_data)\n",
    "exp_dset = TensorDataset(exp_data)\n",
    "\n",
    "exp_loader = DataLoader(\n",
    "    exp_dset,\n",
    "    batch_size=10,\n",
    "    num_workers=0,\n",
    ")\n",
    "sim_loader = DataLoader(\n",
    "    sim_dset,\n",
    "    batch_size=10,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6e0a5b",
   "metadata": {},
   "source": [
    "## Util Functions for Cycle Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8a21f-b778-4776-8dde-59334f05db71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_diffusion(x_0, model):\n",
    "    \"\"\"\n",
    "    Simulates the forward diffusion process in a diffusion model.\n",
    "\n",
    "    Parameters:\n",
    "        x_0 (torch.Tensor): The initial input tensor representing the starting point cloud.\n",
    "        model (object): The diffusion model containing the variance schedule and other parameters.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tensors representing the trajectory of the forward diffusion process. \n",
    "              Each tensor corresponds to an intermediate noisy point cloud at a given timestep.\n",
    "    \"\"\"\n",
    "    diffusion = model.diffusion\n",
    "    num_steps = diffusion.var_sched.num_steps\n",
    "\n",
    "    trajectory = [x_0]\n",
    "\n",
    "    for t in range(1, num_steps + 1):\n",
    "        beta = diffusion.var_sched.betas[t]\n",
    "        c0 = torch.sqrt(beta).view(-1, 1, 1)       \n",
    "        c1 = torch.sqrt(1 - beta).view(-1, 1, 1)   \n",
    "        e_rand = torch.randn_like(x_0)                  \n",
    "        x_t = c1 * trajectory[-1] + c0 * e_rand         \n",
    "        trajectory.append(x_t)\n",
    "\n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8a21f-b778-4776-8dde-59334f05db71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_diffusion(x_0, model):\n",
    "    \"\"\"\n",
    "    Simulates the forward diffusion process in a diffusion model.\n",
    "\n",
    "    Parameters:\n",
    "        x_0 (torch.Tensor): The initial input tensor representing the starting point cloud.\n",
    "        model (object): The diffusion model containing the variance schedule and other parameters.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tensors representing the trajectory of the forward diffusion process. \n",
    "              Each tensor corresponds to an intermediate noisy point cloud at a given timestep.\n",
    "    \"\"\"\n",
    "    diffusion = model.diffusion\n",
    "    num_steps = diffusion.var_sched.num_steps\n",
    "\n",
    "    trajectory = [x_0]\n",
    "\n",
    "    for t in range(1, num_steps + 1):\n",
    "        beta = diffusion.var_sched.betas[t]\n",
    "        c0 = torch.sqrt(beta).view(-1, 1, 1)       \n",
    "        c1 = torch.sqrt(1 - beta).view(-1, 1, 1)   \n",
    "        e_rand = torch.randn_like(x_0)                  \n",
    "        x_t = c1 * trajectory[-1] + c0 * e_rand         \n",
    "        trajectory.append(x_t)\n",
    "\n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5782196b-e981-4748-8cf5-05f952a432da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_point_cloud(point_cloud, sample_index=0):\n",
    "    \"\"\"\n",
    "    Visualize point cloud with charges\n",
    "\n",
    "    Parameters:\n",
    "        point_cloud (torch.Tensor): The initial input batch of tensors representing point clouds.\n",
    "        sample_index: the index of the point cloud to visualize in the batch\n",
    "    \"\"\"\n",
    "    # Extract the sample\n",
    "    sample = point_cloud[sample_index]\n",
    "\n",
    "    # Extract x, y, z coordinates\n",
    "    x = sample[:, 0].numpy()\n",
    "    y = sample[:, 1].numpy()\n",
    "    z = sample[:, 2].numpy()\n",
    "    c = sample[:, 3].numpy()\n",
    "\n",
    "    # Create a 3D plot\n",
    "    fig = plt.figure(figsize=(6,4))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Scatter plot\n",
    "    ax.scatter(x, y, z, c = c, s=2, cmap=plt.cool())\n",
    "\n",
    "    # Setting labels\n",
    "    ax.set_xlabel('X axis')\n",
    "    ax.set_ylabel('Y axis')\n",
    "    ax.set_zlabel('Z axis')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44b4432-9579-49b3-bebe-69d0e1561328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dpm_encoder(x_0, model, context):\n",
    "    \"\"\"\n",
    "    Implementation of the DPM_Encoder.\n",
    "\n",
    "    This function generates a noisy trajectory of point clouds from an initial point cloud `x_0` and\n",
    "    then encodes it using a diffusion model by computing the corresponding noise vectors for each\n",
    "    step in the diffusion process. The function returns the final noisy point cloud and a tensor\n",
    "    of noise vectors.\n",
    "\n",
    "    Parameters:\n",
    "        x_0 (torch.Tensor): The initial input tensor representing the starting point cloud.\n",
    "        model (object): The diffusion model containing the network and variance schedule.\n",
    "        context (torch.Tensor): the latent from pointnet encoder of the DPM model.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - x_T (torch.Tensor): The final noisy point cloud after the forward diffusion process.\n",
    "            - eps_tensor (torch.Tensor): A tensor containing the noise vectors for each step in the diffusion process.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        batch_size, num_point, dim = x_0.shape\n",
    "        traj = forward_diffusion(x_0, model)\n",
    "        diffusion = model.diffusion\n",
    "        \n",
    "        epsilon_list = []\n",
    "        x_T = traj[-1]  # The final noisy point cloud\n",
    "        for t in range(len(traj)-1, 0, -1):\n",
    "            \n",
    "            alpha = diffusion.var_sched.alphas[t]\n",
    "            alpha_bar = diffusion.var_sched.alpha_bars[t]\n",
    "            sigma = diffusion.var_sched.get_sigmas(t, flexibility = 0.1)\n",
    "            \n",
    "            c0 = 1.0 / torch.sqrt(alpha)\n",
    "            c1 = (1 - alpha) / torch.sqrt(1 - alpha_bar)\n",
    "            \n",
    "            beta = diffusion.var_sched.betas[[t]*batch_size]\n",
    "            e_theta = diffusion.net(traj[t], beta=beta, context=context)\n",
    "            mean = c0 * (traj[t] - c1 * e_theta)\n",
    "            epsilon = (traj[t-1] - mean) / sigma\n",
    "            epsilon_list.append(epsilon)\n",
    "        # Convert the list of noise tensors to a single tensor\n",
    "        eps_tensor = torch.stack(epsilon_list, dim=1)\n",
    "    return x_T, eps_tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb14fcb5-7369-40ad-ba74-499c878e2a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, num_points, context, x_T, eps, point_dim=4, flexibility=0.1, ret_traj=False):\n",
    "        \"\"\"\n",
    "        Sample point cloud with the DPM.\n",
    "\n",
    "        Parameters:\n",
    "            model (object): The diffusion model containing the network and variance schedule.\n",
    "            num_points (int): The number of points in the final point cloud.\n",
    "            context (torch.Tensor): The context tensor for conditioning the model.\n",
    "            x_T (torch.Tensor): The initial noisy point cloud.\n",
    "            eps (torch.Tensor): A tensor containing the noise vectors for each step in the reverse diffusion process.\n",
    "            point_dim (int): The dimensionality of each point in the point cloud (default is 4).\n",
    "            flexibility (float): The flexibility parameter for adjusting the diffusion schedule (default is 0.1).\n",
    "            ret_traj (bool): Whether to return the trajectory of intermediate steps (default is False).\n",
    "\n",
    "        Returns:\n",
    "            Union[dict, torch.Tensor]: The trajectory of intermediate steps as a dictionary if `ret_traj` is True, \n",
    "                                    or the final sampled point cloud as a tensor if `ret_traj` is False.\n",
    "        \"\"\"\n",
    "        batch_size = context.size(0)\n",
    "        diffusion = model.diffusion\n",
    "        traj = {diffusion.var_sched.num_steps: x_T}\n",
    "        for t in range(diffusion.var_sched.num_steps, 0, -1):\n",
    "            z = eps[:, diffusion.var_sched.num_steps-t] if t > 1 else torch.zeros_like(x_T)\n",
    "            \n",
    "            alpha = diffusion.var_sched.alphas[t]\n",
    "            alpha_bar = diffusion.var_sched.alpha_bars[t]\n",
    "            sigma = diffusion.var_sched.get_sigmas(t, flexibility)\n",
    "\n",
    "            c0 = 1.0 / torch.sqrt(alpha)\n",
    "            c1 = (1 - alpha) / torch.sqrt(1 - alpha_bar)\n",
    "\n",
    "            x_t = traj[t]\n",
    "            # print(x_t.shape)\n",
    "            beta = diffusion.var_sched.betas[[t]*batch_size]\n",
    "            e_theta = diffusion.net(x_t, beta=beta, context=context)\n",
    "            x_next = c0 * (x_t - c1 * e_theta) + sigma * z\n",
    "            # print(\"NEXT: \", x_next.shape)\n",
    "            traj[t-1] = x_next.detach()     # Stop gradient and save trajectory.\n",
    "            traj[t] = traj[t].cpu()         # Move previous output to CPU memory.\n",
    "            if not ret_traj:\n",
    "                del traj[t]\n",
    "        \n",
    "        if ret_traj:\n",
    "            return traj\n",
    "        else:\n",
    "            return traj[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db88a73a-66af-4510-9ac4-a717d689d332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_point_clouds_side_by_side(point_cloud1, point_cloud2, index, sample_index=0):\n",
    "    \"\"\"\n",
    "    Visualize point cloud with charges for two point clouds side by side\n",
    "\n",
    "    Parameters:\n",
    "        point_cloud1, point_cloud2, (torch.Tensor): The initial input batch of tensors representing point clouds.\n",
    "        sample_index: the index of the point cloud to visualize in the batch\n",
    "    \"\"\"\n",
    "    # Extract the samples\n",
    "    sample1 = point_cloud1[sample_index]\n",
    "    sample2 = point_cloud2[sample_index]\n",
    "\n",
    "    # Extract x, y, z coordinates for both samples\n",
    "    x1, y1, z1, c1 = sample1[:, 0].numpy(), sample1[:, 1].numpy(), sample1[:, 2].numpy(), sample1[:, 3].numpy()\n",
    "    x2, y2, z2, c2 = sample2[:, 0].numpy(), sample2[:, 1].numpy(), sample2[:, 2].numpy(), sample2[:, 3].numpy()\n",
    "    \n",
    "    # Create a figure and a set of subplots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5), subplot_kw={'projection': '3d'})\n",
    "    \n",
    "    # Scatter plot for the first point cloud\n",
    "    pc1 = axs[0].scatter(x1, y1, z1, s=2, cmap='cool', vmin=0, vmax=8000)\n",
    "    axs[0].set_title('Original', weight='bold')\n",
    "    axs[0].set_xlabel('X', weight='bold')\n",
    "    axs[0].set_ylabel('Y', weight='bold')\n",
    "    axs[0].set_zlabel('Z', weight='bold')\n",
    "    axs[0].set_xlim([-1, 1])\n",
    "    axs[0].set_ylim([0, 2])\n",
    "    axs[0].set_zlim([-2, 2])\n",
    "    axs[0].set_xticks([-1, -0.5, 0, 0.5, 1])\n",
    "    axs[0].set_yticks([0, 0.5, 1, 1.5, 2])\n",
    "    axs[0].set_zticks([-2, -1, 0, 1, 2])\n",
    "    axs[0].set_xticklabels([-1, -0.5, 0, 0.5, 1], fontweight='bold')\n",
    "    axs[0].set_yticklabels([0, 0.5, 1, 1.5, 2], fontweight='bold')\n",
    "    axs[0].set_zticklabels([-2, -1, 0, 1, 2], fontweight='bold')\n",
    "    \n",
    "    # Scatter plot for the second point cloud\n",
    "    pc2 = axs[1].scatter(x2, y2, z2, s=2, cmap='cool', vmin=0, vmax=8000)\n",
    "    axs[1].set_title('Translation', weight='bold')\n",
    "    axs[1].set_xlabel('X', weight='bold')\n",
    "    axs[1].set_ylabel('Y', weight='bold')\n",
    "    axs[1].set_zlabel('Z', weight='bold')\n",
    "    axs[1].set_xlim([-1, 1])\n",
    "    axs[1].set_ylim([0, 2])\n",
    "    axs[1].set_zlim([-2, 2])\n",
    "    axs[1].set_xticks([-1, -0.5, 0, 0.5, 1])\n",
    "    axs[1].set_yticks([0, 0.5, 1, 1.5, 2])\n",
    "    axs[1].set_zticks([-2, -1, 0, 1, 2])\n",
    "    axs[1].set_xticklabels([-1, -0.5, 0, 0.5, 1], fontweight='bold')\n",
    "    axs[1].set_yticklabels([0, 0.5, 1, 1.5, 2], fontweight='bold')\n",
    "    axs[1].set_zticklabels([-2, -1, 0, 1, 2], fontweight='bold')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plot{index}.png\", dpi=500)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1901be8f-a080-48d1-b903-27533b6f27ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_point_clouds_reconstruction(point_cloud1, point_cloud2, point_cloud3, index, sample_index=0):\n",
    "    # Extract the samples\n",
    "    sample1 = point_cloud1[sample_index]\n",
    "    sample2 = point_cloud2[sample_index]\n",
    "    sample3 = point_cloud3[sample_index]\n",
    "\n",
    "    # Extract x, y, z coordinates for both samples\n",
    "    x1, y1, z1, c1 = sample1[:, 0].numpy(), sample1[:, 1].numpy(), sample1[:, 2].numpy(), sample1[:, 3].numpy()\n",
    "    x2, y2, z2, c2 = sample2[:, 0].numpy(), sample2[:, 1].numpy(), sample2[:, 2].numpy(), sample2[:, 3].numpy()\n",
    "    x3, y3, z3, c3 = sample3[:, 0].numpy(), sample3[:, 1].numpy(), sample3[:, 2].numpy(), sample3[:, 3].numpy()\n",
    "\n",
    "    # Scaling and transformation\n",
    "    x1 *= 250\n",
    "    x2 *= 250\n",
    "    x3 *= 250\n",
    "    \n",
    "    y1 *= 250\n",
    "    y2 *= 250\n",
    "    y3 *= 250\n",
    "    \n",
    "    z1 = 500 * (z1 - 1)\n",
    "    z2 = 500 * (z2 - 1)\n",
    "    z3 = 500 * (z3 - 1)\n",
    "    \n",
    "    c1 = 10 ** c1\n",
    "    c2 = 10 ** c2\n",
    "    c3 = 10 ** c3\n",
    "\n",
    "    # Create a figure and a set of subplots\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(12, 6), subplot_kw={'projection': '3d'})\n",
    "    \n",
    "    # Scatter plot for the first point cloud\n",
    "    pc1 = axs[0].scatter(x1, z1, y1, s=2, c=c1, cmap='cool', vmin=0, vmax=8000)  \n",
    "    axs[0].set_title('Original', weight='bold')\n",
    "    axs[0].set_xlabel('X')\n",
    "    axs[0].set_ylabel('Z')\n",
    "    axs[0].set_zlabel('Y')\n",
    "    axs[0].set_xlim([-500, 500])\n",
    "    axs[0].set_ylim([-500, 800])\n",
    "    axs[0].set_zlim([-500, 500])\n",
    "    \n",
    "    # Scatter plot for the second point cloud\n",
    "    pc2 = axs[1].scatter(x2, z2, y2, s=2, c=c2, cmap='cool', vmin=0, vmax=8000)  \n",
    "    axs[1].set_title('Translation', weight='bold')\n",
    "    axs[1].set_xlabel('X')\n",
    "    axs[1].set_ylabel('Z')\n",
    "    axs[1].set_zlabel('Y')\n",
    "    axs[1].set_xlim([-500, 500])\n",
    "    axs[1].set_ylim([-500, 800])\n",
    "    axs[1].set_zlim([-500, 500])\n",
    "    \n",
    "    # Scatter plot for the third point cloud (Reconstruction)\n",
    "    pc3 = axs[2].scatter(x3, z3, y3, s=2, c=c2, cmap='cool', vmin=0, vmax=8000) \n",
    "    axs[2].set_title('Reconstruction', weight='bold')\n",
    "    axs[2].set_xlabel('X')\n",
    "    axs[2].set_ylabel('Z')\n",
    "    axs[2].set_zlabel('Y')\n",
    "    axs[2].set_xlim([-500, 500])\n",
    "    axs[2].set_ylim([-500, 800])\n",
    "    axs[2].set_zlim([-500, 500])\n",
    "    \n",
    "    # Show the plot and save\n",
    "    plt.subplots_adjust(wspace=0.3)\n",
    "    cbar = fig.colorbar(pc3, ax=axs, shrink=0.5, aspect=10)\n",
    "    plt.savefig(f\"plot{index}.png\", dpi=500)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406fe03d",
   "metadata": {},
   "source": [
    "## Standard deviation check\n",
    "Used to verify if our model can recognize noise distribution. This is used for the line toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6ba1ef-30ce-4b87-b251-4cb660838f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sim to sim\n",
    "for i, batch in enumerate(exp_loader):\n",
    "    data = batch[0].to(device)\n",
    "    mu_sim, sigma_sim = model_sim.encoder(data)\n",
    "    context_sim = reparameterize_gaussian(mean=mu_sim, logvar=sigma_sim)\n",
    "    \n",
    "    mu_exp, sigma_exp = model_exp.encoder(data)\n",
    "    context_exp = reparameterize_gaussian(mean=mu_exp, logvar=sigma_exp)\n",
    "    \n",
    "    x_T, eps = dpm_encoder(data, model_exp, context_exp)\n",
    "    x_T = x_T.to(device)\n",
    "    eps = eps.to(device)\n",
    "    print(\"successfully encoded\")\n",
    "    x = sample(model_exp, 512, context_exp, x_T, eps)\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        visualize_point_clouds_side_by_side(data, x, sample_index=i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a0f0e6",
   "metadata": {},
   "source": [
    "## Translation of Point Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00daf7a4-bbd4-414e-bce6-021295520ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sim to exp\n",
    "for i, batch in enumerate(sim_loader):\n",
    "    data = batch[0].to(device)\n",
    "    mu_sim, sigma_sim = model_sim.encoder(data)\n",
    "    context_sim = reparameterize_gaussian(mean=mu_sim, logvar=sigma_sim)\n",
    "    \n",
    "    mu_exp, sigma_exp = model_exp.encoder(data)\n",
    "    context_exp = reparameterize_gaussian(mean=mu_exp, logvar=sigma_exp)\n",
    "    \n",
    "    x_T, eps = dpm_encoder(data, model_sim, context_sim)\n",
    "    x_T = x_T.to(device)\n",
    "    eps = eps.to(device)\n",
    "    print(\"successfully encoded\")\n",
    "    x = sample(model_exp, 512, context_exp, x_T, eps)\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        visualize_point_clouds_side_by_side(data, x, i, sample_index=i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6ac1b1-df9d-4dc7-97e8-5b4052695e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp to sim\n",
    "for i, batch in enumerate(exp_loader):\n",
    "    data = batch[0].to(device)\n",
    "    mu_sim, sigma_sim = model_sim.encoder(data)\n",
    "    context_sim = reparameterize_gaussian(mean=mu_sim, logvar=sigma_sim)\n",
    "    \n",
    "    mu_exp, sigma_exp = model_exp.encoder(data)\n",
    "    context_exp = reparameterize_gaussian(mean=mu_exp, logvar=sigma_exp)\n",
    "    \n",
    "    x_T, eps = dpm_encoder(data, model_exp, context_exp)\n",
    "    x_T = x_T.to(device)\n",
    "    eps = eps.to(device)\n",
    "    print(\"successfully encoded\")\n",
    "    x = sample(model_sim, 512, context_sim, x_T, eps)\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        visualize_point_clouds_side_by_side(data, x, i, sample_index=i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc942f47",
   "metadata": {},
   "source": [
    "## Translation of Point Clouds With Reconstruction Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff389ada-bee0-4ed7-9421-45083d930106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstruction test\n",
    "for i, batch in enumerate(exp_loader):\n",
    "    if i == 1:\n",
    "        data = batch[0].to(device)\n",
    "        mu_sim, sigma_sim = model_sim.encoder(data)\n",
    "        context_sim = reparameterize_gaussian(mean=mu_sim, logvar=sigma_sim)\n",
    "\n",
    "        mu_exp, sigma_exp = model_exp.encoder(data)\n",
    "        context_exp = reparameterize_gaussian(mean=mu_exp, logvar=sigma_exp)\n",
    "\n",
    "        x_T, eps = dpm_encoder(data, model_exp, context_exp)\n",
    "        x_T = x_T.to(device)\n",
    "        eps = eps.to(device)\n",
    "        print(\"successfully encoded\")\n",
    "        x = sample(model_sim, 512, context_sim, x_T, eps)\n",
    "\n",
    "        mu_sim2, sigma_sim2 = model_sim.encoder(x)\n",
    "        context_sim2 = reparameterize_gaussian(mean=mu_sim2, logvar=sigma_sim2)\n",
    "\n",
    "        mu_exp2, sigma_exp2 = model_exp.encoder(x)\n",
    "        context_exp2 = reparameterize_gaussian(mean=mu_exp2, logvar=sigma_exp2)\n",
    "\n",
    "        x_T2, eps2 = dpm_encoder(x, model_sim, context_sim2)\n",
    "        x_T2 = x_T2.to(device)\n",
    "        eps2 = eps2.to(device)\n",
    "        print(\"successfully encoded reconstuction\")\n",
    "        x2 = sample(model_exp, 512, context_exp2, x_T2, eps2)\n",
    "\n",
    "        for i in range(len(x)):\n",
    "            visualize_point_clouds_reconstruction(data, x, x2, i, sample_index=i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3290277b-d3e1-4a89-9f97-5354c83a702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstruction test\n",
    "for i, batch in enumerate(sim_loader):\n",
    "    data = batch[0].to(device)\n",
    "    mu_sim, sigma_sim = model_sim.encoder(data)\n",
    "    context_sim = reparameterize_gaussian(mean=mu_sim, logvar=sigma_sim)\n",
    "    \n",
    "    mu_exp, sigma_exp = model_exp.encoder(data)\n",
    "    context_exp = reparameterize_gaussian(mean=mu_exp, logvar=sigma_exp)\n",
    "    \n",
    "    x_T, eps = dpm_encoder(data, model_sim, context_sim)\n",
    "    x_T = x_T.to(device)\n",
    "    eps = eps.to(device)\n",
    "    print(\"successfully encoded\")\n",
    "    x = sample(model_exp, 512, context_exp, x_T, eps)\n",
    "    \n",
    "    mu_sim2, sigma_sim2 = model_sim.encoder(x)\n",
    "    context_sim2 = reparameterize_gaussian(mean=mu_sim2, logvar=sigma_sim2)\n",
    "    \n",
    "    mu_exp2, sigma_exp2 = model_exp.encoder(x)\n",
    "    context_exp2 = reparameterize_gaussian(mean=mu_exp2, logvar=sigma_exp2)\n",
    "    \n",
    "    x_T2, eps2 = dpm_encoder(x, model_exp, context_exp2)\n",
    "    x_T2 = x_T2.to(device)\n",
    "    eps2 = eps2.to(device)\n",
    "    print(\"successfully encoded reconstuction\")\n",
    "    x2 = sample(model_sim, 512, context_sim, x_T2, eps2)\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        visualize_point_clouds_reconstruction(data, x, x2, i, sample_index=i)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpm-pc-gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
